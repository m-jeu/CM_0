{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Research iteration 1</h1>\n",
    "\n",
    "<i>Joël Boafo, Sjoerd Beetsma, Maarten de Jeu\n",
    "Class V2A - Group 5</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "\n",
    "TODO(m-jeu): Place to write a quick introduction to the notebook structure, conventions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Business Understanding</h2>\n",
    "\n",
    "Through the business, we have been asked to examine the following questions:\n",
    "\n",
    "<ol>\n",
    "<li>In hoeverre is de score van een Portugese Red te voorspellen op basis van de chemische kenmerken?</li>\n",
    "<li>Zelf te bepalen: denk aan andere type wijnen of andere landen.</li>\n",
    "<li>Zelf te bepalen: denk bijvoorbeeld aan het clusteren op basis van de chemische kenmerken waarmee het type druif of de regio bepaald kan worden. Of kun je logische clusters vinden van topwijnen, doordrinkwijnen en bocht?</li>\n",
    "</ol>\n",
    "\n",
    "<i>TODO(m-jeu): Either translate these questions to english, or change the language of the rest of the document to dutch. This also goes for the dutch list in 'Data Understanding'.</i>\n",
    "\n",
    "Currently, the exact nature of 'the business' and their desires datascience-wise is unknown to us. This requires further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Understanding </h2>\n",
    "\n",
    "The business tells us the most important variables in the dataset are:\n",
    "\n",
    "<ol>\n",
    "<li>Herkomst van de wijn en type druif.</li>\n",
    "<li>Review van de wijn, inclusief naam van de sommelier en de score op een schaal van 1 tot 100.</li>\n",
    "<li>De uitkomsten van chemische tests op 11 waarde (waaronder suikergehalte, pH, alcoholgehalte, et cetera).</li>\n",
    "\n",
    "We import some libraries, and the dataset. Then we have an initial look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/redwine.csv\", sep=\";\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows seems to correspond with individual wines on first glance, though this does need to be examined more thoroughly. Columns are different attributes for those individual wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature variables</h3>\n",
    "\n",
    "Here we remove the columns: country, variety, description, title, taster_name and id. They are unnecessary for our model in determining the Target, which is points.\n",
    "Country and variety are possible feature variables but are left out for now as the dataset contains only 1 unique country and variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_features_target = dataset.drop(['country', 'variety', 'description', 'title', 'taster_name', 'id'], axis=1)\n",
    "dataset_features_target.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scales of measurements </h3>\n",
    "\n",
    "To construct an appropiate model it's necessary to have a understanding of all the scales of measurements for the target and feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nom, disc, cont = 'Nominal', 'Discrete', 'Continous'\n",
    "vars_scale = [nom, disc, disc, nom, nom, cont, cont, cont, cont, cont, cont, cont, cont, cont, cont, cont ]\n",
    "measurement_scales = pd.DataFrame({'Variable':dataset_features_target.columns, 'Scale of measurement':vars_scale})\n",
    "measurement_scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Central tendancies and dispersion measures</h3>\n",
    "\n",
    "From the central tendancies and dispersion measures we can see some useful statistics about the target and feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_features_target.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be noted the feature variables alcohol, density, citric acid aren't described even though they are of discrete scale, we will look at what's wrong during the data preparation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correlations</h3>\n",
    "\n",
    "To help find positive, negative and neutral correlations matrix is constructed where dark red corresponds to a positive correlation and dark green a negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr = dataset_features_target.corr()\n",
    "plt.figure(figsize=(10,7.5))\n",
    "cmap = sns.diverging_palette(200, 0, as_cmap=True) # color palette as cmap\n",
    "mask = np.logical_not(np.tril(np.ones_like(corr))) # triangle mask\n",
    "sns.heatmap(corr,annot=True, mask=mask, cmap = cmap, vmin=-1, vmax=1) # correlation heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the correlation matrix graph above you can see which attributes have a correlation to other attributes. Starting with our target variable 'quality', we can see quality has a few correlations with the strongest one being alcohol and a few weaker ones like volatile acidity, sulphates and citric acid. Because quality is our target variable it's indepented attribute in the correlation.\n",
    "\n",
    "Besides there are some corelations among chemical properties:\n",
    "Fixed acidity has strong correlation with pH, but it’s still an independent type. pH However is a dependent type; it depends on the former. Volatile acidity, residual sugar, sulphates, chlorides, and density are all independent data types. Total sulfur dioxide is dependent on free sulfur dioxide, but free sulfur dioxide is independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preparation</h2>\n",
    "\n",
    "The data needs some cleaning up. An overview of datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter doesn't recognize some of the Python str objects for what they are, and simply calls them the 'object' type. Let's convert them to the right type to allow for more method flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.convert_dtypes()\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some datatypes in the DataFrame that don't quite correspond to what you'd expect them to be, considering what they represent. Citric acid, Density and Alcohol are string objects, even though you'd expect them to be some kind of number-datatype. Let's copy everyone to a seperate column called 'raw_columnname' so that we can evaluate the original next to the converted in case we run into any problems turning these columns into numbers. Then we'll convert each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problematic_column_names = [\"citric acid\", \"density\", \"alcohol\"]\n",
    "copied_column_names = {f\"raw_{name}\":name for name in problematic_column_names}\n",
    "\n",
    "for new, to_copy in copied_column_names.items():  # Is this allowed?\n",
    "    dataset[new] = dataset[to_copy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preparation on column-by-column basis</h3>\n",
    "\n",
    "<h4>Citric Acid</h4>\n",
    "\n",
    "The citric acid column consists of string objects, through most entries are formatted like floats. Pandas can convert these for us, turning the ones that it can't understand into not-a-number entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"citric acid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"citric acid\"] = pd.to_numeric(dataset[\"citric acid\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's define a simple convenience function that describes the min, max and amount of nan entries in a series object, to quickly gauge the validity of data contained within, and call it on the Citric Acid column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def simple_describe(s: pd.Series, name: str = \"Series object\") -> None:\n",
    "    \"\"\"Print out a simple description of a Pandas Series object that contains numeric values.\n",
    "    That covers min, max and amount of nan/None entries.\n",
    "\n",
    "    Args:\n",
    "        s: Pandas series object with numeric values.\n",
    "        name: optional name for the series to use in the printed description.\"\"\"\n",
    "    print(f\"{name}:\\nmin: {np.min(s)}\\nmax: {np.max(s)}\\n#(nan): {s.isnull().sum()}\")\n",
    "\n",
    "simple_describe(dataset[\"citric acid\"], \"Citric acid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto converting the citric acid table to float leaves us with 203 not-a-number entries. Lets have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"citric acid\"].isnull()][[\"id\", \"title\", \"citric acid\", \"raw_citric acid\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears these data points did not have a value for citric acid to begin with. According to <a href=\"https://wineserver.ucdavis.edu/industry-info/enology/methods-and-techniques/common-chemical-reagents/citric-acid\">this website</a>, citric acid is something that's <i>added</i> to wine most of the time, but it doesn't seem essential. We'll assume that the wines with '-' for citric acid were given this value on purpose, and that this means that there's none in there. Let's replace those values with 0 in the raw table, and use that to create a final version of the citric acid table. Then we'll describe it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset['raw_citric acid'] = dataset['raw_citric acid'].str.replace('-', '0')\n",
    "dataset['citric acid'] = pd.to_numeric(dataset[\"raw_citric acid\"], errors='coerce')\n",
    "simple_describe(dataset['citric acid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citric acid seems clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Density</h4>\n",
    "\n",
    "Most density values are formatted like proper floats, so let's have pandas turn them into that, and then describe it. This time, the simple describe won't quite cut it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"density\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"density\"] = pd.to_numeric(dataset[\"density\"], errors='coerce')\n",
    "dataset[\"density\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description, we see that almost all values (the mininum, and all quartiles) fall around the 0.99 range. Let's examine the spread of data further with the help of a frequency graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(dataset[\"density\"], bins=50)  # TODO(m-jeu): Use OOP API and make clearer\n",
    "plt.gca().set(title=\"Density frequency\", xlabel=\"Density\", ylabel=\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most measurements fall around the '0.99' mark. Though some fall around the 10, and a couple fall around the 100 mark. We will assume that this is a notation error, where the dots weren't placed right, which can fairly easily be accounted for. If we assume that all measurements are supposed to be around '1', because it wouldn't be realistic for wines to have a 10x or 100x difference in density with others, we can correct for the mistake by recursively dividing the number by 10, until a more sensible measurement is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def divide_until_at(num: float,\n",
    "                    target: float,\n",
    "                    divide_by: float,\n",
    "                    delta: float,\n",
    "                    max_recursions: int = 0) -> float:\n",
    "    \"\"\"Recursively divide a number until it's either within a certain range of a target number,\n",
    "    or the max number of recursions is reached.\n",
    "\n",
    "    Args:\n",
    "        num: input number to divide.\n",
    "        target: target number to get within a certain range of.\n",
    "        divide_by: number to divide input number by.\n",
    "        delta: amount of distance the input number could be from the target number to be considered a success.\n",
    "        max_recursion: amount of recursion after which the function should give up.\n",
    "\n",
    "    Returns:\n",
    "        num divided by divide_by a certain amount of times, so that it's within delta of target.\n",
    "        amount of times num is divided can also be 0.\n",
    "        None if max_recursions gets violated.\"\"\"\n",
    "    if max_recursions < 0:\n",
    "        return None\n",
    "    if abs(num - target) < delta:\n",
    "        return num\n",
    "    return divide_until_at((num / divide_by), target, divide_by, delta, (max_recursions - 1))\n",
    "\n",
    "dataset[\"density\"] = dataset[\"density\"].apply(lambda x: divide_until_at(x, 1, 10, 0.1, 2))\n",
    "dataset[\"density\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_describe(dataset[\"density\"], \"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weird numbers have been taken care of. A single not-a-number entry remains. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"density\"].isnull()][['id', 'title', 'density', 'raw_density']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single wine has a density of '.', which we can't really use for anything. To keep the data pure, let's drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"density\"].notna()]\n",
    "simple_describe(dataset[\"density\"], \"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density is clean!\n",
    "\n",
    "<h4>Alcohol</h4>\n",
    "\n",
    "Most alcohol percentages are formatted like proper floats, and can be converted automatically. This allows us to analyse the actual numbers as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"alcohol\"] = pd.to_numeric(dataset[\"alcohol\"], errors='coerce')  # No OOP interface.\n",
    "simple_describe(dataset[\"alcohol\"], \"Alcohol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alcohol-percentages we have been able to extract from the String objects seem to fall within the boundaries of what could reasonably be considered 'wine'. We are still left with 10 not-a-numbers entries where pandas wasn't able to convert the strings to numbers. Let's have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"alcohol\"].isnull()][['id', 'title', 'designation', 'alcohol']]  # TODO(m-jeu): This can probably be made prettier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering only 10 wines are missing data, we can probably look these up by hand. The percentages are based on these sources:\n",
    "\n",
    "<a href=\"https://www.internationalwinechallenge.com/canopy/beverage_details?wid=44074\">1344. </a><a href=\"https://www.winemag.com/buying-guide/companhia-das-quintas-2009-quinta-da-fronteira-seleccao-do-enologo-red-douro/\">1345. </a><a href=\"https://www.winemag.com/buying-guide/quinta-das-bandeiras-2010-passagem-reserva-red-douro/\">1620. </a><a href=\"https://www.nataliemaclean.com/wine-reviews/quinta-da-rede-reserva-2015/317025\">1670. </a><a href=\"https://www.winemag.com/buying-guide/terra-silvestre-2014-grande-reserva-red-tejo-portuguese-red/\">1764. </a><a href=\"https://www.vivino.com/NL/en/adega-cooperativa-de-borba-alentejo-reserva-tinto/w/1235048?year=2013\">1765. </a><a href=\"https://www.winemag.com/buying-guide/adega-cooperativa-cartaxo-2012-bridao-classico-red-tejo/\">1766. </a><a href=\"https://www.winemag.com/buying-guide/quinta-da-lagoalva-de-cima-2015-lagoalva-barrel-selection-red-tejo/\">1794. </a><a href=\"https://www.winemag.com/buying-guide/quinta-do-casal-branco-2014-lobo-e-falcao-reserva-red-tejo/\">1795. </a><a href=\"https://www.wine-searcher.com/find/ramos+pinto+duas+quinta+rsrv+douro+portugal/2006/netherlands#t2\">2028. </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assignments use numeric row index, and not 'id' column. Might break when working on the id column.\n",
    "dataset.loc[1344, \"alcohol\"] = 14.0\n",
    "dataset.loc[1345, \"alcohol\"] = 14.5\n",
    "dataset.loc[1620, \"alcohol\"] = 14.0\n",
    "dataset.loc[1670, \"alcohol\"] = 13.5\n",
    "dataset.loc[1764, \"alcohol\"] = 13.5\n",
    "dataset.loc[1765, \"alcohol\"] = 14.0\n",
    "dataset.loc[1766, \"alcohol\"] = 14.0\n",
    "dataset.loc[1794, \"alcohol\"] = 14.0\n",
    "dataset.loc[1795, \"alcohol\"] = 14.0\n",
    "dataset.loc[2028, \"alcohol\"] = 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets' have a look how many nan entries are left in the alcohol column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"alcohol\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dropping unneeded columns</h3>\n",
    "\n",
    "We drop columns description, title, taster_name and id, because they are not useful for later models, and hold no sway over our target variable, points. We also drop raw_citric acid, raw_density and raw_alcohol because they are no longer needed in data preparation.\n",
    "\n",
    "Leaving us with a dataset containing clean target and feature variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['country', 'variety', 'description', 'title', 'taster_name', 'id', 'raw_citric acid', 'raw_density', 'raw_alcohol'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO(sbeetsma): 'Alentejano' probably doesn't exist as province, and they mean 'Alentejo'. Should probably check this and add source before implementing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
