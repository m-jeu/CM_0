{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837436ab",
   "metadata": {},
   "source": [
    "<h1> Research iteration 2</h1>\n",
    "\n",
    "<i>JoÃ«l Boafo, Sjoerd Beetsma, Maarten de Jeu\n",
    "Class V2A - Group 5</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2cbadc",
   "metadata": {},
   "source": [
    "<h2>Business Understanding</h2>\n",
    "\n",
    "Through the business, we have been asked to examine the following questions:\n",
    "\n",
    "<ol>\n",
    "<li>With what accuracy can we decide the quality of a red-wine according to its chemical properties.</li>\n",
    "<li>Can we predict a wine's color based on it's chemical properties?</li>\n",
    "<li>Can we distinguish between logical clusters of wineries? (Premium, budget, high-quality, etc...)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45ad40",
   "metadata": {},
   "source": [
    "<h2> Data Understanding: Chemical datasets.</h2>\n",
    "\n",
    "The dataset for the first research question is aquired from https://archive.ics.uci.edu/ml/datasets/wine+quality along a dataset about red-wine there is also a dataset about white-wine lets explore both for possible research-questions in the future.\n",
    "\n",
    "The business tells us the variables in the chemical datasets are:<br />\n",
    "\n",
    "1 - fixed acidity <br />\n",
    "2 - volatile acidity <br />\n",
    "3 - citric acid <br />\n",
    "4 - residual sugar <br />\n",
    "5 - chlorides <br />\n",
    "6 - free sulfur dioxide <br />\n",
    "7 - total sulfur dioxide <br />\n",
    "8 - density <br />\n",
    "9 - pH <br />\n",
    "10 - sulphates <br />\n",
    "11 - alcohol <br />\n",
    "12 - quality (score between 0 and 10, based on sensory data) <br />\n",
    "\n",
    "The business also let us now that they don't know if all variables are relevant in deciding the quality score of a wine.\n",
    "\n",
    "For the second research question we aquired the dataset from ...\n",
    "The business told us the dataset has the following variables:\n",
    "\n",
    "1 - country<br/>\n",
    "2 - description<br/>\n",
    "3 - designation<br/>\n",
    "4 - points<br/>\n",
    "5 - price<br/>\n",
    "6 - province <br/>\n",
    "7 - region_1<br/>\n",
    "8 - region_2<br/>\n",
    "9 - taster_name<br/>\n",
    "10 - taster_twitter_handle<br/>\n",
    "11 - title <br/>\n",
    "12 - variety<br/>\n",
    "13 - winery<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e40312",
   "metadata": {},
   "source": [
    "We import some libraries and the dataset to examine the data through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import py_lib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126710ed",
   "metadata": {},
   "source": [
    "Load in both red and white wine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red = pd.read_csv(\"datasets/winequality-red.csv\", sep=\";\")\n",
    "dataset_white = pd.read_csv(\"datasets/winequality-white.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193babcb",
   "metadata": {},
   "source": [
    "Lets take the head of one of the chemical property datasets to have a first look at the submissions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c946f",
   "metadata": {},
   "source": [
    "As described by the business each row seems to correspond with a individual wine with eleven different columns describing chemical properties and one column which represents the quality score of the wine.\n",
    "\n",
    "Lets see howmuch raw-data we have through the shapes of the datasets before we do any more exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_rows, red_columns = dataset_red.shape\n",
    "white_rows, white_columns = dataset_white.shape\n",
    "\n",
    "print(f'The red-wine quality dataset contains {red_rows} rows and {red_columns} columns')\n",
    "print(f'The white-wine quality dataset contains {white_rows} rows and {white_columns} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3d190",
   "metadata": {},
   "source": [
    "Lets change the column name white spaces to underscores to make life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a78400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.columns = dataset_red.columns.str.replace(' ','_')\n",
    "dataset_white.columns = dataset_white.columns.str.replace(' ','_')\n",
    "\n",
    "dataset_red.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de320c",
   "metadata": {},
   "source": [
    "<h3>Target and feature variables</h3>\n",
    "\n",
    "All the columns describing chemical properties will be considered as a feature variable and the column quality represents the target variable, the variable we want to predict.\n",
    "Lets safe them in a variables for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5511e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vars = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol'] \n",
    "target_var = 'quality'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f52c8",
   "metadata": {},
   "source": [
    "All the columns describing the origin of the wine and the category will be considered as a feature variable. The column 'points' represents the target variable we want to predict.\n",
    "We will also store them in variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f694a27e",
   "metadata": {},
   "source": [
    "<h3> Scales of measurements </h3>\n",
    "\n",
    "To choose a appropiate model for our research-questions and available data it's necessary to have a understanding of all the scales of measurements for the target and feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792898fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomi, disc, ordi, cont = 'Nominal', 'Discrete', 'Ordinal','Continous'\n",
    "print('Scales of measurement chemical properties datasets')\n",
    "pd.DataFrame(index=dataset_red.columns, data=[cont for i in range(11)] + [disc], columns=['Scale_of_measurement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488508a6",
   "metadata": {},
   "source": [
    "As can be seen all the chemical properties (feature variables) have continous scale of measurement and the target variable, quality has a Discrete scale of measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435838e9",
   "metadata": {},
   "source": [
    "<h3>Central tendancies and dispersion measures</h3>\n",
    "\n",
    "From the central tendancies and dispersion measures we can see some useful statistics about the target and feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c251f48",
   "metadata": {},
   "source": [
    "From the describe we can tell that there are quite a few columns with a big difference between maximum and minimum values which indicate outliers.\n",
    "\n",
    "The columns with big differences between max and min values:\n",
    "Residual_sugar, chlorides, free_sulfur_dioxide ,total_sulfur_dioxide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7bd21",
   "metadata": {},
   "source": [
    "Just like the red-wine dataset, the white-wine dataset has similair differences in maximum and minimum values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a645879",
   "metadata": {},
   "source": [
    "<h3>Distribution of data</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e70c2a",
   "metadata": {},
   "source": [
    "Lets take a more visual look at the distribution of all data through a histogram for each of the feature and target attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673bdc4",
   "metadata": {},
   "source": [
    "Starting off with the red wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af007820",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.hist(figsize=(15,15))\n",
    "plt.show()  #FIXME(m-jeu): Is this necessary, because the visualization is through a pandas method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b2053",
   "metadata": {},
   "source": [
    "Moving on to the white wine dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.hist(figsize=(15,15))\n",
    "plt.show()  #FIXME(m-jeu): Is this necessary, because the visualization is through a pandas method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf04f2",
   "metadata": {},
   "source": [
    "As can been seen in the tables above the quality scores for the red wines range between 3 and 8 with wines with a score of 5 being the most common.\n",
    "The white wines range within a quality of 3 and 9 with the score of 6 being most common."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a90b10",
   "metadata": {},
   "source": [
    "<h3>Outliers</h3>\n",
    "\n",
    "To get a visual understanding of the outliers in the feature columns each feature gets a boxplotted with the target variable points. Giving a small summary of the minimum, Q1, Q2 (median), Q3 and the maximum of each attribute plotted against points scored to give a view of outliers at all quality levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d42488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplotter(dataset, y_axes, x_axis):\n",
    "    \"\"\"Function to boxplot 1 x_axis against a list of y_axis of a given dataset\"\"\"\n",
    "    for col in y_axes:\n",
    "        sns.boxplot(x=dataset[x_axis], y=dataset[col])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68a1e5",
   "metadata": {},
   "source": [
    "First boxplot all the feature variables against the target variable of the red-wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a04dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotter(dataset=dataset_red, y_axes=feature_vars, x_axis=target_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdda52",
   "metadata": {},
   "source": [
    "Now do the same for the white-wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7475571",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplotter(dataset=dataset_white, y_axes=feature_vars, x_axis=target_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a0b24",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As can be seen from the boxplots all of our current variables contain outliers.\n",
    "\n",
    "All outliers in the above boxplots seem to be plausible and not from incorrect data.\n",
    "From the boxplot with alcohol on the y axis and quality on the x axis we can  see that a trend of a rising median alcohol percentage the higher the quality of the wine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79895d99",
   "metadata": {},
   "source": [
    "<h3>Correlations</h3>\n",
    "\n",
    "To help find correlations between variables and indepented/undepented attributes we can make use of a correlation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f47eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix_plotter(dataset, title=''):\n",
    "    \"\"\"Return a correlation matrix created using seaborn and matplotlib that for all columns in\n",
    "    a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        dataset: Dataset to construct correlation matrix for.\n",
    "        title: Title of the plot.\n",
    "\n",
    "    Returns:\n",
    "        correlation matrix.\"\"\"\n",
    "    corr = dataset.corr()\n",
    "    plt.figure(figsize=(10,7.5))\n",
    "    cmap = sns.diverging_palette(200, 0, as_cmap=True) # color palette as cmap\n",
    "    mask = np.logical_not(np.tril(np.ones_like(corr))) # triangle mask\n",
    "    sns.heatmap(corr, annot=True, mask=mask, cmap = cmap, vmin=-1, vmax=1).set_title(title) # correlation heatmap\n",
    "    plt.show()\n",
    "corr_matrix_plotter(dataset_red, 'red-wine')\n",
    "corr_matrix_plotter(dataset_white, 'white-wine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122293e",
   "metadata": {},
   "source": [
    "In the correlation matrices graphed above you can see which attributes have a correlation to other attributes. Starting with our target variable 'quality', we can see quality has a few correlations with the strongest one being alcohol for both red and white wines and a few weaker ones like volatile acidity, sulphates and citric acid for red wines and density and chloride for white wines. Because quality is our target variable it's the indepented attribute in the correlations.\n",
    "\n",
    "Besides there are some corelations among chemical properties:\n",
    "Fixed acidity has strong correlation with pH, but itâs still an independent type. pH However is a dependent type; it depends on the former. Volatile acidity, residual sugar, sulphates, chlorides, and density are all independent data types. Total sulfur dioxide is dependent on free sulfur dioxide, but free sulfur dioxide is independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e1a65",
   "metadata": {},
   "source": [
    "<h3>Data Preparation: Chemical dataset.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c720bd",
   "metadata": {},
   "source": [
    "Lets start of the data preparation by checking the datatypes and clean or change them if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1b2b5",
   "metadata": {},
   "source": [
    "Red-wine quality datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489a509",
   "metadata": {},
   "source": [
    "White-wine quality datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7362924",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703501d",
   "metadata": {},
   "source": [
    "We can now move on to checking and removing any NA values in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11665efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(dataset_red).sum().sum() # checking for total NA values in red_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(dataset_white).sum().sum() # checking for total NA values in white_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a07fa",
   "metadata": {},
   "source": [
    "<h4>Removing outliers</h4>\n",
    "A remove outliers function is created but currently not used because for linear regression we want to keep the outliers.\n",
    "Lets start of by removing all extreme the outliers leaving the mild ones in the dataset with a outer fence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dataset, fence = 3):\n",
    "    q1 = dataset.quantile(.25)\n",
    "    q3 = dataset.quantile(.75)\n",
    "    iqr = q3 - q1\n",
    "    return dataset[(dataset >= q1 - (fence * iqr)) & (dataset <= q3 + (fence * iqr))].dropna() # turn extreme outliers into NaN values and drop the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae470263",
   "metadata": {},
   "source": [
    "The red-wine dataset contained 1599 rows and the white-wine 4898 before removing the outliers lets remove the outliers and check howmany are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe428d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red = remove_outliers(dataset_red)\n",
    "dataset_white = remove_outliers(dataset_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd11941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_red.shape, dataset_white.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d6367",
   "metadata": {},
   "source": [
    "There are still 1435 rows left which means 12% of the columns contained outliers. With 88% still left there will be enough data to construct a model. \n",
    "There is roughly still 88% of the red-wine data left and 96% of the white-wine data after removing the extreme outliers that lay 3+ IQR above Q3 or 3+ IQR below Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9717c81",
   "metadata": {},
   "source": [
    "<h3>Normalizing data</h3>\n",
    "\n",
    "Many algorithms used for making a prediction model work more efficient with normalized data. We can normalize the whole dataset into a new dataframe to acces normalized data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(dataset):\n",
    "    scaler = sk.preprocessing.StandardScaler().fit(dataset)\n",
    "    return pd.DataFrame((scaler.transform(dataset)), columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset_red = normalizer(dataset_red)\n",
    "normalized_dataset_white = normalizer(dataset_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6531cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset_red.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbeef0a",
   "metadata": {},
   "source": [
    "<h4>Data cleaned</h4>\n",
    "\n",
    "The red and white wine chemicalproperty datasets got cleaned by removing all extreme outliers in the datasets and creating a normalized copy of both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17860fcb",
   "metadata": {},
   "source": [
    "<h3>Modeling: Chemical datasets</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c56189",
   "metadata": {},
   "source": [
    "<h4>Test and train data</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c508b",
   "metadata": {},
   "source": [
    "The datasets will be splitted into a train and test dataset for the models to learn and test their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red, y_red = dataset_red[feature_vars], dataset_red[target_var]\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_red, y_red, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d13b4",
   "metadata": {},
   "source": [
    "<h4>Baseline model</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14b152",
   "metadata": {},
   "source": [
    "A baseline model is constructed to compared future models against. The baseline model always predicts the mean of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_red = py_lib.DumbRegressor(y_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e613af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_line_predictions_red = baseline_red.predict(X_test_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed735751",
   "metadata": {},
   "source": [
    "Lets check the root mean squared error to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.metrics.mean_squared_error(y_test_red, base_line_predictions_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9276b27",
   "metadata": {},
   "source": [
    "Plotting the predicted value (a constant) and the actual values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(base_line_predictions_red, c='r')\n",
    "plt.scatter(x=np.arange(len(X_test_red)), y=y_test_red)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba3727",
   "metadata": {},
   "source": [
    "<h4>Implementing a machine learning model</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c84b81",
   "metadata": {},
   "source": [
    "For the first version of the machine learning model both linear regression and polynomial regression will be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11724674",
   "metadata": {},
   "source": [
    "Making the pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73708d9",
   "metadata": {},
   "source": [
    "<h4>Hyper-parameters</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c577d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = make_pipeline(linear_model.LinearRegression())\n",
    "poly = make_pipeline(PolynomialFeatures(polynomials),linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ed5b9",
   "metadata": {},
   "source": [
    "Fit the model to the X train and y train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train_red, y_train_red)\n",
    "poly.fit(X_train_red, y_train_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12707a69",
   "metadata": {},
   "source": [
    "predict the y value of the X test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8383b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions_red_lin = regr.predict(X_test_red)\n",
    "y_predictions_red_poly = poly.predict(X_test_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d99d3c",
   "metadata": {},
   "source": [
    "Get the mean_squared_error to see how good the prediction is vs the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_RMSE = sk.metrics.mean_squared_error(y_test_red, y_predictions_red_lin)\n",
    "poly_RMSE = sk.metrics.mean_squared_error(y_test_red, y_predictions_red_poly)\n",
    "print(f\"RMSE linear model {lin_RMSE} RMSE multi-polynomial model {poly_RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b534d",
   "metadata": {},
   "source": [
    "Scatterplot of the two most correlating columns and the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(x=X_test_red['alcohol'], y=X_test_red['sulphates'], z=y_predictions_red_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac93627",
   "metadata": {},
   "source": [
    "Scatterplot of the two most correlating columns and the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(x=X_test_red['alcohol'], y=X_test_red['sulphates'], z=y_test_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae3f9e",
   "metadata": {},
   "source": [
    "<h3>Conclusion first model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67688992",
   "metadata": {},
   "source": [
    "Conclusion to be added. First model requires more tuning and adjusting before a final conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9e956",
   "metadata": {},
   "source": [
    "<h3>Research question 3</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505acbc",
   "metadata": {},
   "source": [
    "<h2> Business understanding </h2>\n",
    "\n",
    "For our third research question we got a dataset about winereviews from different sommeliers with information about the origin of the wine, price and their review.\n",
    "<br/>\n",
    "With our research question being:\n",
    "<li>Can we distinguish between logical clusters of wineries? (Premium, budget, high-quality, etc...)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1289210",
   "metadata": {},
   "source": [
    "<h2> Data Understanding Wine-review dataset.</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc7e55",
   "metadata": {},
   "source": [
    "We'll be using the review Dataset for research question 3, so that needs to be examined as well.\n",
    "\n",
    "From our dataset's source ... we got a list of the different attributes:\n",
    "\n",
    "1 - country<br/>\n",
    "2 - description<br/>\n",
    "3 - designation<br/>\n",
    "4 - points<br/>\n",
    "5 - price<br/>\n",
    "6 - province <br/>\n",
    "7 - region_1<br/>\n",
    "8 - region_2<br/>\n",
    "9 - taster_name<br/>\n",
    "10 - taster_twitter_handle<br/>\n",
    "11 - title <br/>\n",
    "12 - variety<br/>\n",
    "13 - winery<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429edd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reviews = pd.read_csv(\"datasets/winemag-data-130k-v2.csv\")\n",
    "dataset_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74178dd5",
   "metadata": {},
   "source": [
    "At first look it appears most of the (usable) variables are nominal, with points and price as the only numerical (discrete) values. We have some columns that initially seem fairly useless for the types of analysis that we will most probably be using for this project, like 'description', but we'll keep them just in case we end up doing anything like a sentiment-analysis type model. It also appears we have a redundant index columns called \"Unnamed: 0\".\n",
    "\n",
    "<h4>Target and feature variables</h4>\n",
    "\n",
    "We're not quite sure what feature variables we'll be using for the third question, but we know we'll be grouping by 'winery'. We'll start out by using 'price' and 'points' as further feature variables, but during the modelling stage we might end up using more.\n",
    "\n",
    "Considering we're looking for logical clusters (unsupervised learning), there are no target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e3915",
   "metadata": {},
   "source": [
    "<h4>Scales of measurement</h4>\n",
    "\n",
    "Like mentioned earlier, we're mostly dealing with categorical (ordinal, specifically) variables in this dataset. There are 2 numerical values. Points and price are both discrete values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c00b2d",
   "metadata": {},
   "source": [
    "<h4>Central tendencies and dispersion measures</h4>\n",
    "\n",
    "We can examine the spread of values of the numerical variables through histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec836e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dataset_reviews[[\"price\", \"points\"]].hist()  # _ = to prevent pointless table from showing on screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541bc6d",
   "metadata": {},
   "source": [
    "Points has an obvious Gaussian distribution. It does appear the price graph is made quite unreadable by some outliers. We'll have a proper look at those later, let's ignore them for now to have a better look at the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237865d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reviews[dataset_reviews[\"price\"] < 100][\"price\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c377d3",
   "metadata": {},
   "source": [
    "It appears that the price column in lognormally distributed.\n",
    "\n",
    "<h4>Outliers</h4>\n",
    "\n",
    "Because we won't be comparing against something, we'll be using a seperate way of creating boxplots to explore outliers for the numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edafd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset_reviews[[\"points\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898f234",
   "metadata": {},
   "source": [
    "It appears the median' amount of points is around 88, and quite symmetric. There are a couple of outliers around 100, but nothing extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69310e39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset_reviews[[\"price\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236d9dd",
   "metadata": {},
   "source": [
    "The boxplot for price is barely a boxplot because of all the outliers. Like we already noticed with the histogram, most measurements fall within the 0-100 range, but there are some extremely high outliers. For data exploration, we'll create a separate column with the outliers removed for price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f2ada",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_reviews[\"price_no_outliers\"] = remove_outliers(dataset_reviews[\"price\"])  # FIXME(m-jeu): remove_outliers drops na\n",
    "dataset_reviews[\"points_no_outliers\"] = remove_outliers(dataset_reviews[\"points\"])# Which then get filled in again..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39163893",
   "metadata": {},
   "source": [
    "<h3>Correlations</h3>\n",
    "\n",
    "We'll use the pearson correlation coefficient to see if there's a linear correlation between the only 2 numerical columns in the dataset. Because of the extreme outliers in price, it might be sensible to also check this with the outliers removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0158d61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_reviews[[\"points\", \"price\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f294fdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_reviews[[\"points_no_outliers\", \"price_no_outliers\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa42c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It appears there is a weak linear correlation between price and points, when disregarding outliers. Because we're looking for cluster, this is not terribly relevant, but still noteworthy.\n",
    "\n",
    "<h2>Data preparation: Review dataset</h2>\n",
    "\n",
    "Having explored the data, we're ready to clean it up. We have already separated the outliers in a separate column in the dataset, because that couldn't wait until data preparation. First, let's get rid of the unnamed index column, because that's not useful in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cec5f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_reviews.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "dataset_reviews.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302be9e",
   "metadata": {},
   "source": [
    "And let's change the categorical values from 'object', to 'string', to 'category'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d8155",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_reviews = dataset_reviews.convert_dtypes()\n",
    "dataset_reviews[[\"country\", \"description\", \"designation\", \"province\", \"region_1\", \"region_2\", \"taster_name\", \"taster_twitter_handle\", \"title\", \"variety\", \"winery\"]] = dataset_reviews[[\"country\", \"description\", \"designation\", \"province\", \"region_1\", \"region_2\", \"taster_name\", \"taster_twitter_handle\", \"title\", \"variety\", \"winery\"]].astype(\"category\")  # FIXME(m-jeu): This can probably be written shorter.\n",
    "dataset_reviews.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009409e",
   "metadata": {},
   "source": [
    "<h2>Modelling: Review dataset</h2>\n",
    "\n",
    "Our goal is to find logical clusters for different types of wineries, using a clustering algorithm. First, we create a separate dataframe from the original dataframe grouped by winery, with the mean value of the point/price value of that winery's wine as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c76f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_winery = dataset_reviews.groupby(\"winery\")[[\"price_no_outliers\", \"points_no_outliers\"]].mean()\n",
    "dataset_winery.dropna(inplace=True)\n",
    "dataset_winery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3982e",
   "metadata": {},
   "source": [
    "For many clustering algorithms, it's useful to have the data normalized as well. Let's do that in seperate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f8bc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize a pandas series object by subtracting the mean and dividing by the\n",
    "    standard deviation.\n",
    "\n",
    "    Args:\n",
    "        s: series object to normalize.\n",
    "\n",
    "    Returns:\n",
    "        normalized series object.\"\"\"\n",
    "    return (s - np.mean(s)) / np.std(s)\n",
    "\n",
    "dataset_winery[\"price_normalized\"] = normalize(dataset_winery[\"price_no_outliers\"])\n",
    "dataset_winery[\"points_normalized\"] = normalize(dataset_winery[\"points_no_outliers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748cb36",
   "metadata": {},
   "source": [
    "Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49943533",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(dataset_winery[\"price_normalized\"], dataset_winery[\"points_normalized\"], s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeb544",
   "metadata": {},
   "source": [
    "So far, it mostly just looks like a thick cloud. Hopefully, a clustering algorithm will be able to see through the fog and give us more insight.\n",
    "\n",
    "We'll start out by using kMeans on the (normalised) points and price because of it's simplicity, and move onto using more complex models and/or adding more data in case it doesn't give any useful results.\n",
    "Even though it's doubtful anything with k > 20 will be useful, we'll still try everything from k=2 to k=30, to see how the model behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4bf040",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#c1 for clustering attempt 1\n",
    "c1_k = np.arange(2, 31)  # Values for k to try out.\n",
    "c1_make_train_km_model = np.vectorize(lambda k: cluster.KMeans().set_params(n_clusters=k, random_state=0).fit(dataset_winery[[\"price_normalized\", \"points_normalized\"]]))  # FIXME(m-jeu): Unreadable!\n",
    "c1_models = c1_make_train_km_model(c1_k)\n",
    "c1_models_scores = np.vectorize(lambda m: m.score(dataset_winery[[\"price_normalized\", \"points_normalized\"]]))(c1_models)  #FIXME(m-jeu): Unreadable?\n",
    "plt.plot(c1_k, c1_models_scores, 'bx-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3920878",
   "metadata": {},
   "source": [
    "Considering the fact there's no clear 'elbow' in the elbow plot, and no clear clusters in the previously constructed graph, it doesn't look very promising. We can look at a visualization at k=6\n",
    "of the result to confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ff3d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c1_final_model = c1_models[4]  # Take it out of array for convenience.\n",
    "c1_predictions = c1_final_model.predict(dataset_winery[[\"price_normalized\", \"points_normalized\"]])\n",
    "plt.scatter(dataset_winery[\"price_no_outliers\"], dataset_winery[\"points_no_outliers\"], c=c1_predictions, s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6ecc6",
   "metadata": {},
   "source": [
    "Like we expected, not very useful. It's doubtful another algorithm would be able to make sense out of that cloud, so the way to go is probably to attempt to use the curse of dimensionality to our advantage.\n",
    "There is one problem: there isn't much numerical data available to use in our models. All the categorical values in the dataset are nominal, so that would mean using a get_dummies() construction to turn them into useful data. Unfortunately, all the nominal variables have too many permutations to realistically use, so we'll have to get creative.\n",
    "\n",
    "In interesting metric could be the amount of wine reviews listed for a single winery. We'll create a new grouped by dataframe, with this column added, normalize it's columns, and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318320b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_reviews[\"winery\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b2869",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_winery_2 = dataset_reviews.groupby(\"winery\").agg({\"price_no_outliers\": np.mean,\n",
    "                                                          \"points_no_outliers\": np.mean,\n",
    "                                                          \"title\": lambda np_a: np_a.size})  # Title is a random column\n",
    "                                                                                             # Doesn't really matter what column\n",
    "                                                                                             # We pick here\n",
    "\n",
    "dataset_winery_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c858234",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_winery_2[\"price_normalized\"] = normalize(dataset_winery_2[\"price_no_outliers\"])\n",
    "dataset_winery_2[\"points_normalized\"] = normalize(dataset_winery_2[\"points_no_outliers\"])\n",
    "dataset_winery_2[\"reviews_normalized\"] = normalize(dataset_winery_2[\"title\"])\n",
    "dataset_winery_2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef32577",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_frame=dataset_winery_2,\n",
    "              x='price_normalized',\n",
    "              y='points_normalized',\n",
    "              z='reviews_normalized')\n",
    "\n",
    "fig.update_traces(marker={'size': 1, 'colorscale': 'Viridis', 'opacity': 0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa58514",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "It doesn't seem like this is going anywhere. TODO(m-jeu): Ask Rick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faed88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
