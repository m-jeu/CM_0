{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Red wine data analysis </h2>\n",
    "\n",
    "<h2> Data understanding </h2>\n",
    "\n",
    "\n",
    "Provided are the links to the source of our datasets:\n",
    "\n",
    "https://www.kaggle.com/zynicide/wine-reviews/version/4\n",
    "https://archive.ics.uci.edu/ml/datasets/wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business tells us the variables in the reviews dataset are:<br/>\n",
    "1 - country<br/>\n",
    "2 - description<br/>\n",
    "3 - designation<br/>\n",
    "4 - points<br/>\n",
    "5 - price<br/>\n",
    "6 - province <br/>\n",
    "7 - region_1<br/>\n",
    "8 - region_2<br/>\n",
    "9 - taster_name<br/>\n",
    "10 - taster_twitter_handle<br/>\n",
    "11 - title <br/>\n",
    "12 - variety<br/>\n",
    "13 - winery<br/>\n",
    "<br/>\n",
    "The business does not know if all variables are relevant in deciding the points score of the wine.<br/>\n",
    "\n",
    "We import some libraries and the dataset to examine the data through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_dataset = pd.read_csv(\"datasets/winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance we can see a wide range of countries and regions. It will be interesting to see if we can find a link between the assigned points of the wine, and where it's from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Target and feature variables</h3>\n",
    "\n",
    "All the columns describing the origin of the wine and the category will be considered as a feature variable. The column 'points' represents the target variable we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vars_reviews = ['country','designation', 'price','province','region_1','region_2','variety','winery']\n",
    "target_var_reviews = ['points']\n",
    "feature_target_vars_reviews = ['country','designation', 'price','province','region_1','region_2','variety','winery','points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scales of measurements</h3>\n",
    "\n",
    "To construct an appropiate model it's necessary to have a understanding of all the scales of measurements for the target and feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom, disc, cont = 'Nominal', 'Discrete', 'Continous'\n",
    "var_scale = [nom,nom,cont,nom,nom,nom,nom,nom,disc]\n",
    "measurement_scales = pd.DataFrame(index=review_dataset[feature_target_vars_reviews].columns, data =var_scale, columns =['Scale_of_measurement'])\n",
    "measurement_scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that most of the feature variables are nominal, with the exception bein price which is continious. Our target variable is discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correlations</h3>\n",
    "\n",
    "Below we check the direct correlation between price and point in a scatterplot. Since these are our only numeric values in de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = review_dataset[feature_target_vars_reviews].corr()\n",
    "plt.figure(figsize=(10,7.5))\n",
    "sns.scatterplot(data = review_dataset, x='price', y='points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scatterplot above we can see some interesting findings. If we look at the price between the 500 and 100 it's very difficult to find a wine with points lower than 90. There are ofcourse plenty of wines that score 90 or higher that are below the 500 price mark, but the chance of finding one below 90 is also a lot higher. \n",
    "From this graph we find out that most of the time, the higher you go in price, the more sure you can be of the quality. an interesting finding to take into our model. The correlating number is 0.42 which means there certainly is some form of correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data preparation</h2>\n",
    "\n",
    "Here is an overview of datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset[feature_target_vars_reviews].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected from our scale of measurment earlier; the points are integers and the prices are floats. All our other features are objects. lets convert them to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset = review_dataset[feature_target_vars_reviews].convert_dtypes()\n",
    "review_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dropping NA price values</h3>\n",
    "\n",
    "Since price is our only numeric value and has quite a strong correlation with our target variable, we are gonna drop all the rows that don't have that included. 8996 rows will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset['price'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset = review_dataset.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset['price'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dropping unneeded columns </h3>\n",
    "\n",
    "Earlier we kept using review_dataset[feature_target_vars_reviews] to show all the variables we uses. now we make that our standard dataset to make the modelling process easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset = review_dataset[feature_target_vars_reviews]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}